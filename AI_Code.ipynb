{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb00662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab62f4e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/College/Level 3/1st Semester/Artificial Intelligence (Amr Ghoneim)/Project/Project_Code/A_Z Handwritten Data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Split data the X - Our data , and y - the prdict label\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m,axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read the data...\n",
    "data = pd.read_csv(r\"D:/College/Level 3/1st Semester/Artificial Intelligence (Amr Ghoneim)/Project/Project_Code/A_Z Handwritten Data.csv\").astype('float32')\n",
    "\n",
    "# Split data the X - Our data , and y - the prdict label\n",
    "X = data.drop('0',axis = 1)\n",
    "y = data['0']\n",
    "\n",
    "\n",
    "# Reshaping the data in csv file so that it can be displayed as an image...\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2)\n",
    "train_x = np.reshape(train_x.values, (train_x.shape[0], 28,28))\n",
    "test_x = np.reshape(test_x.values, (test_x.shape[0], 28,28))\n",
    "\n",
    "\n",
    "print(\"Train data shape: \", train_x.shape)\n",
    "print(\"Test data shape: \", test_x.shape)\n",
    "\n",
    "# Dictionary for getting characters from index values...\n",
    "word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}\n",
    "\n",
    "\n",
    "# Plotting the number of alphabets in the dataset...\n",
    "\n",
    "train_yint = np.int0(y)\n",
    "count = np.zeros(26, dtype='int')\n",
    "for i in train_yint:\n",
    "    count[i] +=1\n",
    "\n",
    "alphabets = []\n",
    "for i in word_dict.values():\n",
    "    alphabets.append(i)\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(10,10))\n",
    "ax.barh(alphabets, count)\n",
    "\n",
    "plt.xlabel(\"Number of elements \")\n",
    "plt.ylabel(\"Alphabets\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defeb4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffling the data ...\n",
    "shuff = shuffle(train_x[:100])\n",
    "\n",
    "fig, ax = plt.subplots(3,3, figsize = (10,10))\n",
    "axes = ax.flatten()\n",
    "\n",
    "for i in range(9):\n",
    "    axes[i].imshow(np.reshape(shuff[i], (28,28)), cmap=\"Greys\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Reshaping the training & test dataset so that it can be put in the model...\n",
    "\n",
    "train_X = train_x.reshape(train_x.shape[0],train_x.shape[1],train_x.shape[2],1)\n",
    "print(\"New shape of train data: \", train_X.shape)\n",
    "\n",
    "test_X = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2],1)\n",
    "print(\"New shape of train data: \", test_X.shape)\n",
    "\n",
    "\n",
    "# Converting the labels to categorical values...\n",
    "\n",
    "train_yOHE = to_categorical(train_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of train labels: \", train_yOHE.shape)\n",
    "\n",
    "test_yOHE = to_categorical(test_y, num_classes = 26, dtype='int')\n",
    "print(\"New shape of test labels: \", test_yOHE.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model...\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128,activation =\"relu\"))\n",
    "model.add(Dense(64,activation =\"relu\"))\n",
    "\n",
    "model.add(Dense(26,activation =\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e27470",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=1, min_lr=0.0001)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62227338",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_X, train_yOHE, batch_size=32, epochs=15, callbacks=[reduce_lr, early_stop],  validation_data = (test_X,test_yOHE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ddc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.save(r'model_hand.h5')\n",
    "\n",
    "\n",
    "# Displaying the accuracies & losses for train & validation set...\n",
    "\n",
    "print(\"The validation accuracy is :\", history.history['val_accuracy'])\n",
    "print(\"The training accuracy is :\", history.history['accuracy'])\n",
    "print(\"The validation loss is :\", history.history['val_loss'])\n",
    "print(\"The training loss is :\", history.history['loss'])\n",
    "\n",
    "\n",
    "\n",
    "#Making model predictions...\n",
    "\n",
    "pred = model.predict(test_X[:9])\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying some of the test images & their predicted labels...\n",
    "\n",
    "fig, axes = plt.subplots(3,3, figsize=(8,9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    img = np.reshape(test_X[i], (28,28))\n",
    "    ax.imshow(img, cmap=\"Greys\")\n",
    "    pred = word_dict[np.argmax(test_yOHE[i])]\n",
    "    ax.set_title(\"Prediction: \"+pred)\n",
    "    ax.grid()\n",
    "\n",
    "\n",
    "# Prediction on external image...\n",
    "\n",
    "img = cv2.imread(r'D:/College/Level 3/1st Semester/Artificial Intelligence (Amr Ghoneim)/Project/Project_Code/img_h.jpg')\n",
    "img_copy = img.copy()\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img, (400,440))\n",
    "\n",
    "img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
    "img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "_, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "img_final = cv2.resize(img_thresh, (28,28))\n",
    "img_final =np.reshape(img_final, (1,28,28,1))\n",
    "\n",
    "\n",
    "img_pred = word_dict[np.argmax(model.predict(img_final))]\n",
    "\n",
    "cv2.putText(img, \"Dataflair _ _ _ \", (20,25), cv2.FONT_HERSHEY_TRIPLEX, 0.7, color = (0,0,230))\n",
    "cv2.putText(img, \"Prediction: \" + img_pred, (20,410), cv2.FONT_HERSHEY_DUPLEX, 1.3, color = (255,0,30))\n",
    "cv2.imshow('Dataflair handwritten character recognition _ _ _ ', img)\n",
    "\n",
    "\n",
    "while (1):\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
